# Site name.  Many das2 servers can be located at the same site, please
# use the same SITE_NAME for all the das2 servers in a given organization.

SITE_TITLE = "My Data Source Site"

# A nicer name for the server
SERVER_NAME = "%(SERVER_ID)s"

# Identify this server seperatly in combined logs, will be reduced to lower case
SERVER_ID = "%(SERVER_ID)s"


# Contact email.  You can use replacement characters to obscure the address
# a bit, for example:
#
#   &#45;  '-'
#   @#46;  '.'
#   &#64;  '@'
#   &#117; 'u'

CONTACT_EMAIL = "update&#45;das2server&#46;conf&#64;nowhere&#45;ed&#117;"

# A contact page for the person responsible for the server
CONTACT_URL  = "https://update-das2server.conf.nowhere.edu/~someone/"

# The top location of any dsdf files
DSDF_ROOT = "%(PREFIX)s/datasets"

# if using authentication, the name of the group and users files
USER_PASSWD = "%(PREFIX)s/etc/passwd"
USER_GROUP  = "%(PREFIX)s/etc/group"

# The module path for loading utilities and handles, there can be
# more than one entry, seperate them via ':' characters, no matter
# the operating systems default pathsep character.
MODULE_PATH = "%(PREFIX)s/lib:%(PREFIX)s/lib/python%(PYVER)s"

# The directory for binaries that don't have an explicit path, separate
# multiple paths with ':'
BIN_PATH = "%(PREFIX)s/bin"

# A directory to set for loading shared objects, separate multiple
# paths with ':'
LIB_PATH = "%(PREFIX)s/lib"

# Where to put log files.  You should probably pick an alternate location
LOG_PATH = "%(PREFIX)s/log"

# The URL to the das2_srvcgi_logrdr program.  If this value doesn't
# contain '//' then it is assumed to be relative to the path to the 
# parent of the das2_srvcgi_main script.  If '//' is present it is 
# assumed to be an absolute link
VIEW_LOG_URL = "log"

# The URL to the das2_srvcgi_main program.  If this value doesn't
# contain '//' then it is assumed to be relative to the path to the 
# parent of the das2_srvcgi_log script.  If '//' is present it is 
# assumed to be an absolute link
MAIN_SRV_URL = "server"


# Restricting the das2_srvcgi_logrdr program to only allow local LAN
# traffic is part of your Apache setup.
VIEW_LOG_ALLOW = 127.0.0.1

# A sample dataset to use when testing the front page.  Pick your favorite
# dataset to highlight.
SAMPLE_DSDF = "Examples/Spectra"
SAMPLE_START = 1979-03-01T12:26:11
SAMPLE_END = 1979-03-01T12:29:24

# Ignore Redirects in DSDF files, useful for testing new servers
IGNORE_REDIRECT = false

# Path to various resource files, such as style sheets, logos, etc
# Should contain das2server.xsl, and a logo.*.
RESOURCE_PATH = "%(PREFIX)s/static"

# Provide links to other das2 servers you run, or use (or just know
# about :)
PEERS_FILE = "%(PREFIX)s/etc/das2peers.ini"

# Program used to upconvert das1 streams.  Only used by the U. Iowa group
DAS1_TO_DAS2 = "das2_from_das1"

# The absolute filesystem path to the data cache, only used if caching has 
# been enabled in one or more DSDF files.  You might want to pick an alternate
# location
CACHE_ROOT = "%(PREFIX)s/cache"

# Set the default stream reducer. DSDFs can override this setting for individal
# datasets using the 'reducer=' directive.
D2S_REDUCER = "das2_bin_avgsec"

# Set the default cache reader.  DSDFs can override this setting for individual
# datasets using the 'cacheReader=' directive.
D2S_CACHE_RDR = "das2_cache_rdr"

# Sent the default delimited text values converter.  DSDFs can override
# this setting for individual data sources using the 'csvConverter='
# directive.
D2S_CSV_CONVERTER = "das2_csv"

# Set default das2 binary to das2 text stream converter, datasources can
# override this usin the 'textConverter=' directive.
D2S_TO_UTF8 = "das2_ascii"

# If you are serving QStreams as well as Das2 streams, put the name of your
# default QStream reducer here.
#QDS_REDUCER = qds_bin_avgsec
#QDS_CACHE_RDR = qds_cache_rdr

#QDS_TO_UTF8 = qds_ascii

# Auto-authentication, this is used to setup test servers that can download
# data from all streams for testing without authentication.  This uses the
# remote IP address, so no host names here.  Network ranges have not been
# implemented, so list full host IP addresses.  This has not been tested with
# IPv6 at this time.
# TEST_FROM = 192.168.0.10 192.168.0.11
#
# WARNING:  Clients with the IP addresses listed below will never be
#           asked to athenticate *any* data source.
TEST_FROM = 127.0.0.1

# Das2 CGI scripts can record jobs to be preformed later, such as building
# data caches.  Since many CGI instances may be running at a single time a
# distributed work queue broker is used to handling the task queue.  By 
# default redis is the only broker supported.  If you don't want to allow
# background tasks, or das2_svr_arbiter is not running then comment out the
# setting below.

WORK_QUEUE_BROKER = redis

# This is the information needed to connect to the work queue broker listed
# above.  Connection parameters are separated by colons, for redis the 
# connection parameters are:
#
#    host : port : database_num   
#

WORK_QUEUE_CONN = localhost:6379:0

# PNG Image generator script, will be provided the following command line
# arguments (with value examples):  
#
# in.fmt=das2.2
# time.max=2013-03-01
# time.min=2013-03-02
#
# The program must take a das2.2 stream, or Q stream on it's standard input
# channel and output a PNG image.  See the das2-pyserver user's guide for
# details.
#
#PNG_MAKER = autoplot_url2png.py

# Turn this on to enable support for heliophysics API services
#ENABLE_HAPI_SUBSYS = true

# ########################################################################## #
# Federated Catalog Integration  See docs/FedCat.md for more information.

# Site wide tag (RFC-4151).  
# SITE_CATALOG_TAG = "tag:CHANGE.ME,2021"

# Site ID for references from "tag:das2.org,2012:site:/"
# SITE_ID = mysite
